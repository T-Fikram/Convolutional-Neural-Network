{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a444111a",
   "metadata": {},
   "source": [
    "**Blok 1: Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import copy\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0845e7",
   "metadata": {},
   "source": [
    "**Blok 2: Cek GPU dan Setup Device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ab84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  current_device = torch.cuda.current_device()\n",
    "  gpu_properties = torch.cuda.get_device_properties(current_device)\n",
    "  print(f\"GPU Name: {gpu_properties.name}\")\n",
    "  print(f\"GPU Memory: {gpu_properties.total_memory / 1024**3:.2f} GB\")\n",
    "  print(f\"GPU Compute Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n",
    "else:\n",
    "  print(\"No GPU available, using CPU\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30dc18f",
   "metadata": {},
   "source": [
    "**Blok 3: Setup Path dan Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee418d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Check if directories exist\n",
    "print(\"Checking dataset structure...\")\n",
    "if os.path.exists(train_dir) and os.path.exists(test_dir):\n",
    "  train_classes = os.listdir(train_dir)\n",
    "  test_classes = os.listdir(test_dir)\n",
    "  print(f\"Train classes: {train_classes}\")\n",
    "  print(f\"Test classes: {test_classes}\")\n",
    "    \n",
    "  # Count number of images per class\n",
    "  print(\"\\nNumber of images per class in train set:\")\n",
    "  for class_name in train_classes:\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "      num_images = len(os.listdir(class_path))\n",
    "      print(f\"  {class_name}: {num_images} images\")\n",
    "\n",
    "  print(\"\\nNumber of images per class in test set:\")\n",
    "  for class_name in test_classes:\n",
    "    class_path = os.path.join(test_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "      num_images = len(os.listdir(class_path))\n",
    "      print(f\"  {class_name}: {num_images} images\")\n",
    "else:\n",
    "  print(f\"Error: Dataset directories not found!\")\n",
    "  print(f\"Train directory: {train_dir}\")\n",
    "  print(f\"Test directory: {test_dir}\")\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09012554",
   "metadata": {},
   "source": [
    "**Blok 4: Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 4: Exploratory Data Analysis (EDA)\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPLORATORY DATA ANALYSIS (EDA)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Analisis Struktur Dataset\n",
    "print(\"\\nüìÅ DATASET STRUCTURE ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check folder structure\n",
    "def analyze_folder_structure(base_path):\n",
    "    structure = {}\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        level = root.replace(base_path, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:3]:  # Show only 3 files per folder\n",
    "            print(f'{subindent}{file}')\n",
    "        if len(files) > 3:\n",
    "            print(f'{subindent}... and {len(files)-3} more files')\n",
    "    \n",
    "    return structure\n",
    "\n",
    "print(\"Train directory structure:\")\n",
    "analyze_folder_structure(train_dir)\n",
    "\n",
    "print(\"\\nTest directory structure:\")\n",
    "analyze_folder_structure(test_dir)\n",
    "\n",
    "# 2. Analisis Distribusi Kelas\n",
    "print(\"\\nüìä CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Get class names from folder structure\n",
    "class_names = sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])\n",
    "print(f\"Found {len(class_names)} emotion classes:\")\n",
    "for i, cls in enumerate(class_names):\n",
    "    print(f\"  {i}. {cls}\")\n",
    "\n",
    "# Count images per class in train and test sets\n",
    "train_counts = {}\n",
    "test_counts = {}\n",
    "\n",
    "for cls in class_names:\n",
    "    train_cls_path = os.path.join(train_dir, cls)\n",
    "    test_cls_path = os.path.join(test_dir, cls)\n",
    "    \n",
    "    if os.path.exists(train_cls_path):\n",
    "        train_counts[cls] = len([f for f in os.listdir(train_cls_path) \n",
    "                                if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    \n",
    "    if os.path.exists(test_cls_path):\n",
    "        test_counts[cls] = len([f for f in os.listdir(test_cls_path) \n",
    "                               if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Train set bar chart\n",
    "train_values = [train_counts.get(cls, 0) for cls in class_names]\n",
    "bars1 = axes[0, 0].bar(class_names, train_values, color='skyblue')\n",
    "axes[0, 0].set_title('Class Distribution - Train Set', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Emotion Classes')\n",
    "axes[0, 0].set_ylabel('Number of Images')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 20,\n",
    "                   f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Test set bar chart\n",
    "test_values = [test_counts.get(cls, 0) for cls in class_names]\n",
    "bars2 = axes[0, 1].bar(class_names, test_values, color='lightgreen')\n",
    "axes[0, 1].set_title('Class Distribution - Test Set', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Emotion Classes')\n",
    "axes[0, 1].set_ylabel('Number of Images')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                   f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Train set pie chart\n",
    "train_total = sum(train_values)\n",
    "train_percentages = [v/train_total*100 for v in train_values]\n",
    "axes[1, 0].pie(train_percentages, labels=class_names, autopct='%1.1f%%', \n",
    "               colors=plt.cm.Set3(np.arange(len(class_names))/len(class_names)))\n",
    "axes[1, 0].set_title('Percentage Distribution - Train Set', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Class imbalance ratio\n",
    "imbalance_ratios = {}\n",
    "for cls in class_names:\n",
    "    if train_counts[cls] > 0:\n",
    "        imbalance_ratios[cls] = train_counts[cls] / min(train_counts.values())\n",
    "\n",
    "axes[1, 1].bar(class_names, [imbalance_ratios.get(cls, 0) for cls in class_names], \n",
    "               color='salmon')\n",
    "axes[1, 1].set_title('Class Imbalance Ratio (vs Min Class)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Emotion Classes')\n",
    "axes[1, 1].set_ylabel('Imbalance Ratio')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].axhline(y=1, color='r', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Analisis Statistik Dataset\n",
    "print(\"\\nüìà DATASET STATISTICS SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "total_train = sum(train_counts.values())\n",
    "total_test = sum(test_counts.values())\n",
    "total_all = total_train + total_test\n",
    "\n",
    "print(f\"Total Training Images: {total_train:,}\")\n",
    "print(f\"Total Test Images: {total_test:,}\")\n",
    "print(f\"Total Images: {total_all:,}\")\n",
    "\n",
    "print(\"\\nPer-class Statistics:\")\n",
    "for cls in class_names:\n",
    "    train_count = train_counts.get(cls, 0)\n",
    "    test_count = test_counts.get(cls, 0)\n",
    "    train_percent = train_count/total_train*100 if total_train > 0 else 0\n",
    "    test_percent = test_count/total_test*100 if total_test > 0 else 0\n",
    "    \n",
    "    print(f\"\\n  {cls.upper()}:\")\n",
    "    print(f\"    Train: {train_count:6d} images ({train_percent:5.1f}%)\")\n",
    "    print(f\"    Test:  {test_count:6d} images ({test_percent:5.1f}%)\")\n",
    "    print(f\"    Total: {train_count + test_count:6d} images\")\n",
    "\n",
    "# 4. Visualisasi Sample Images\n",
    "print(\"\\nüñºÔ∏è SAMPLE IMAGES VISUALIZATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, cls in enumerate(class_names[:7]):  # Show 7 classes\n",
    "    cls_path = os.path.join(train_dir, cls)\n",
    "    if os.path.exists(cls_path):\n",
    "        # Get random image\n",
    "        images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if images:\n",
    "            img_name = np.random.choice(images)\n",
    "            img_path = os.path.join(cls_path, img_name)\n",
    "            \n",
    "            # Load image\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # Display\n",
    "            axes[idx].imshow(img, cmap='gray')\n",
    "            axes[idx].set_title(f'{cls}\\n{img.size[0]}x{img.size[1]}', \n",
    "                               fontsize=12, fontweight='bold')\n",
    "            axes[idx].axis('off')\n",
    "            \n",
    "            # Add image statistics\n",
    "            img_array = np.array(img)\n",
    "            axes[idx].text(0.5, -0.15, \n",
    "                          f'Range: [{img_array.min():3.0f}, {img_array.max():3.0f}]\\nMean: {img_array.mean():5.1f}, Std: {img_array.std():5.1f}',\n",
    "                          transform=axes[idx].transAxes, ha='center', fontsize=9,\n",
    "                          bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "        else:\n",
    "            axes[idx].axis('off')\n",
    "            axes[idx].set_title(f'{cls}\\n(No images)', fontsize=12)\n",
    "    else:\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'{cls}\\n(Not found)', fontsize=12)\n",
    "\n",
    "# Hide unused subplot\n",
    "axes[7].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images from Each Emotion Class (48x48 grayscale)', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Insights dari EDA\n",
    "print(\"\\nüí° EDA INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"1. DATA DISTRIBUTION:\")\n",
    "print(f\"   ‚Ä¢ Dataset memiliki {len(class_names)} kelas emosi\")\n",
    "print(f\"   ‚Ä¢ Total {total_all:,} gambar (Train: {total_train:,}, Test: {total_test:,})\")\n",
    "print(f\"   ‚Ä¢ Rasio train/test: {total_train/total_test:.2f}:1\")\n",
    "\n",
    "print(\"\\n2. CLASS IMBALANCE:\")\n",
    "max_imbalance = max(imbalance_ratios.values()) if imbalance_ratios else 1\n",
    "print(f\"   ‚Ä¢ Ketidakseimbangan maksimum: {max_imbalance:.1f}x\")\n",
    "print(f\"   ‚Ä¢ Rekomendasi: Gunakan class weighting atau oversampling\")\n",
    "\n",
    "print(\"\\n3. IMAGE CHARACTERISTICS:\")\n",
    "print(\"   ‚Ä¢ Semua gambar: 48x48 piksel, grayscale\")\n",
    "print(\"   ‚Ä¢ Perlu: Konversi ke RGB untuk ResNet, Resize ke 224x224\")\n",
    "\n",
    "print(\"\\n4. DATA AUGMENTATION NEEDS:\")\n",
    "print(\"   ‚Ä¢ Wajah memiliki variasi pose dan ekspresi\")\n",
    "print(\"   ‚Ä¢ Rekomendasi: Horizontal flip, rotation, color jitter\")\n",
    "\n",
    "print(\"\\n‚úÖ EDA completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15eb00d",
   "metadata": {},
   "source": [
    "**Blok 5: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 5: Data Preprocessing Strategy\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA PREPROCESSING STRATEGY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüéØ OBJECTIVES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. Menyiapkan data untuk model ResNet50\")\n",
    "print(\"2. Mengatasi ketidakseimbangan kelas\")\n",
    "print(\"3. Meningkatkan generalisasi dengan augmentasi\")\n",
    "print(\"4. Normalisasi untuk training stabil\")\n",
    "\n",
    "print(\"\\nüîß PREPROCESSING PIPELINE:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. INPUT LAYER (Grayscale ‚Üí RGB):\")\n",
    "print(\"   ‚Ä¢ Convert grayscale ke 3 channel (RGB)\")\n",
    "print(\"   ‚Ä¢ Reason: ResNet50 pretrained dengan ImageNet (RGB)\")\n",
    "print(\"   ‚Ä¢ Method: PIL.Image.convert('RGB')\")\n",
    "\n",
    "print(\"\\n2. RESIZING (48x48 ‚Üí 224x224):\")\n",
    "print(\"   ‚Ä¢ Resize semua gambar ke 224x224\")\n",
    "print(\"   ‚Ä¢ Reason: Input size standar ResNet50\")\n",
    "print(\"   ‚Ä¢ Method: torchvision.transforms.Resize()\")\n",
    "\n",
    "print(\"\\n3. DATA AUGMENTATION (Training Only):\")\n",
    "print(\"   ‚Ä¢ RandomHorizontalFlip: p=0.5 (wajah simetris)\")\n",
    "print(\"   ‚Ä¢ RandomRotation: ¬±15 derajat\")\n",
    "print(\"   ‚Ä¢ RandomAffine: Translasi ¬±10%, Scale ¬±10%\")\n",
    "print(\"   ‚Ä¢ ColorJitter: Brightness & contrast ¬±20%\")\n",
    "print(\"   ‚Ä¢ RandomGrayscale: p=0.1 untuk robustness\")\n",
    "print(\"   ‚Ä¢ GaussianBlur: Simulasi ketidakfokusan\")\n",
    "\n",
    "print(\"\\n4. NORMALIZATION:\")\n",
    "print(\"   ‚Ä¢ Mean: [0.485, 0.456, 0.406]\")\n",
    "print(\"   ‚Ä¢ Std: [0.229, 0.224, 0.225]\")\n",
    "print(\"   ‚Ä¢ Reason: Statistik ImageNet untuk transfer learning\")\n",
    "print(\"   ‚Ä¢ Formula: (image - mean) / std\")\n",
    "\n",
    "print(\"\\n5. CLASS IMBALANCE HANDLING:\")\n",
    "print(\"   ‚Ä¢ Weighted CrossEntropyLoss\")\n",
    "print(\"   ‚Ä¢ Weight = total_samples / (n_classes * class_samples)\")\n",
    "print(\"   ‚Ä¢ Efek: Memberi perhatian lebih ke kelas minoritas\")\n",
    "\n",
    "print(\"\\nüîÑ TRANSFORMATION DIFFERENCES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"TRAINING SET:\")\n",
    "print(\"  ‚Ä¢ Full augmentation\")\n",
    "print(\"  ‚Ä¢ Heavy transformations\")\n",
    "print(\"  ‚Ä¢ Untuk meningkatkan generalisasi\")\n",
    "\n",
    "print(\"\\nVALIDATION/TEST SETS:\")\n",
    "print(\"  ‚Ä¢ Hanya resize dan normalisasi\")\n",
    "print(\"  ‚Ä¢ No augmentation\")\n",
    "print(\"  ‚Ä¢ Untuk evaluasi yang fair dan konsisten\")\n",
    "\n",
    "print(\"\\nüìä VISUALIZING TRANSFORMATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create sample transformations for visualization\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load a sample image\n",
    "sample_class = class_names[0]\n",
    "sample_path = os.path.join(train_dir, sample_class)\n",
    "sample_images = [f for f in os.listdir(sample_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "if sample_images:\n",
    "    sample_img_path = os.path.join(sample_path, sample_images[0])\n",
    "    sample_img = Image.open(sample_img_path).convert('RGB')\n",
    "    \n",
    "    # Apply different transforms\n",
    "    transforms_to_show = [\n",
    "        (\"Original\", transforms.Compose([transforms.Resize((224, 224))])),\n",
    "        (\"Random Flip\", transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(p=1.0)\n",
    "        ])),\n",
    "        (\"Rotation 15¬∞\", transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomRotation(15)\n",
    "        ])),\n",
    "        (\"Color Jitter\", transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "        ])),\n",
    "        (\"Grayscale\", transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomGrayscale(p=1.0)\n",
    "        ])),\n",
    "        (\"Normalized\", transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ]))\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, (title, transform) in enumerate(transforms_to_show):\n",
    "        try:\n",
    "            transformed = transform(sample_img)\n",
    "            if isinstance(transformed, torch.Tensor):\n",
    "                # Denormalize for display\n",
    "                if title == \"Normalized\":\n",
    "                    img_np = transformed.numpy().transpose(1, 2, 0)\n",
    "                    img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                    img_np = np.clip(img_np, 0, 1)\n",
    "                    axes[idx].imshow(img_np)\n",
    "                else:\n",
    "                    axes[idx].imshow(transformed.numpy().transpose(1, 2, 0))\n",
    "            else:\n",
    "                axes[idx].imshow(transformed)\n",
    "            \n",
    "            axes[idx].set_title(title, fontsize=12, fontweight='bold')\n",
    "            axes[idx].axis('off')\n",
    "        except Exception as e:\n",
    "            axes[idx].text(0.5, 0.5, f\"Error\\n{e}\", ha='center', va='center')\n",
    "            axes[idx].set_title(title, fontsize=12, fontweight='bold')\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Data Preprocessing & Augmentation Examples', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No sample images found for visualization\")\n",
    "\n",
    "print(\"\\n‚úÖ Data Preprocessing Strategy siap diimplementasikan!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c659b",
   "metadata": {},
   "source": [
    "**Blok 6: Data Transforms dan Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b14fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced data transformations with heavy augmentation\n",
    "train_transform = v2.Compose([\n",
    "  v2.Resize((224, 224)),  # Resize for ResNet\n",
    "  v2.RandomHorizontalFlip(p=0.5),\n",
    "  v2.RandomRotation(degrees=15),\n",
    "  v2.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "  v2.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "  v2.RandomGrayscale(p=0.1),\n",
    "  v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "  v2.ToImage(),\n",
    "  v2.ToDtype(torch.float32, scale=True),\n",
    "  v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "  v2.Resize((224, 224)),\n",
    "  v2.ToImage(),\n",
    "  v2.ToDtype(torch.float32, scale=True),\n",
    "  v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = val_transform  # Same as validation transform\n",
    "\n",
    "print(\"Data transforms defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a22ed",
   "metadata": {},
   "source": [
    "**Blok 7: Load Dataset dengan ImageFolder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets using ImageFolder\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "try:\n",
    "  train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "  test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
    "    \n",
    "  # Get class names\n",
    "  class_names = train_dataset.classes\n",
    "  print(f\"Class names: {class_names}\")\n",
    "  print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "  print(f\"Training samples: {len(train_dataset)}\")\n",
    "  print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "  # Split train into train and validation (90% train, 10% validation)\n",
    "  train_size = int(0.9 * len(train_dataset))\n",
    "  val_size = len(train_dataset) - train_size\n",
    "\n",
    "  train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size]\n",
    "  )\n",
    "    \n",
    "  # Apply validation transform to validation set\n",
    "  val_dataset.dataset = copy.deepcopy(val_dataset.dataset)\n",
    "  val_dataset.dataset.transform = val_transform\n",
    "\n",
    "  print(f\"After split - Training samples: {len(train_dataset)}\")\n",
    "  print(f\"After split - Validation samples: {len(val_dataset)}\")\n",
    "  print(f\"After split - Test samples: {len(test_dataset)}\")\n",
    "\n",
    "except Exception as e:\n",
    "  print(f\"Error loading datasets: {e}\")\n",
    "  # Create dummy datasets for demonstration if real datasets not available\n",
    "  from torchvision.datasets import FakeData\n",
    "\n",
    "  train_dataset = FakeData(size=28000, image_size=(3, 48, 48), num_classes=7, \n",
    "                        transform=train_transform)\n",
    "  val_dataset = FakeData(size=3500, image_size=(3, 48, 48), num_classes=7, \n",
    "                        transform=val_transform)\n",
    "  test_dataset = FakeData(size=3500, image_size=(3, 48, 48), num_classes=7, \n",
    "                        transform=test_transform)\n",
    "  class_names = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5609ea44",
   "metadata": {},
   "source": [
    "**Blok 8: Create DataLoaders dan Calculate Class Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522da23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders with optimal settings\n",
    "train_loader = DataLoader(\n",
    "  train_dataset, \n",
    "  batch_size=batch_size, \n",
    "  shuffle=True, \n",
    "  num_workers=4,\n",
    "  pin_memory=True if torch.cuda.is_available() else False,\n",
    "  persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "  val_dataset, \n",
    "  batch_size=batch_size, \n",
    "  shuffle=False, \n",
    "  num_workers=4,\n",
    "  pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  test_dataset, \n",
    "  batch_size=batch_size, \n",
    "  shuffle=False, \n",
    "  num_workers=4,\n",
    "  pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")\n",
    "\n",
    "# Calculate class weights for imbalanced data\n",
    "def calculate_class_weights(loader, num_classes=7):\n",
    "  class_counts = torch.zeros(num_classes)\n",
    "  for _, labels in loader:\n",
    "    for i in range(num_classes):\n",
    "      class_counts[i] += (labels == i).sum()\n",
    "    \n",
    "  total = class_counts.sum()\n",
    "  class_weights = total / (num_classes * class_counts)\n",
    "  return class_counts, class_weights\n",
    "\n",
    "class_counts, class_weights = calculate_class_weights(train_loader, num_classes)\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "  print(f\"  {class_name}: {class_counts[i]:.0f} samples\")\n",
    "\n",
    "print(f\"\\nClass weights: {class_weights}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_names, class_counts.cpu().numpy())\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xlabel('Emotion Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22735d8d",
   "metadata": {},
   "source": [
    "**Blok 9: Load Pretrained ResNet50 dan Modifikasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionResNet50(nn.Module):\n",
    "  def __init__(self, num_classes=7, dropout_rate=0.5):\n",
    "    super(EmotionResNet50, self).__init__()\n",
    "        \n",
    "    # Load pretrained ResNet50\n",
    "    self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        \n",
    "    # Freeze early layers (first 4 blocks)\n",
    "    for name, param in self.backbone.named_parameters():\n",
    "      if 'layer1' in name or 'layer2' in name or 'layer3' in name:\n",
    "        param.requires_grad = False\n",
    "      else:\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # Replace the final fully connected layer\n",
    "    in_features = self.backbone.fc.in_features\n",
    "        \n",
    "    self.backbone.fc = nn.Sequential(\n",
    "      nn.Dropout(p=dropout_rate),\n",
    "      nn.Linear(in_features, 1024),\n",
    "      nn.BatchNorm1d(1024),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Dropout(p=dropout_rate-0.2),\n",
    "      nn.Linear(1024, 512),\n",
    "      nn.BatchNorm1d(512),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Dropout(p=dropout_rate-0.3),\n",
    "      nn.Linear(512, num_classes)\n",
    "    )\n",
    "        \n",
    "    # Initialize the new layers\n",
    "    self._initialize_weights(self.backbone.fc)\n",
    "    \n",
    "  def _initialize_weights(self, module):\n",
    "    for m in module.modules():\n",
    "      if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "          nn.init.constant_(m.bias, 0)\n",
    "      elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.backbone(x)\n",
    "\n",
    "# Initialize model\n",
    "try:\n",
    "  model = EmotionResNet50(num_classes=num_classes, dropout_rate=0.5)\n",
    "  model = model.to(device)\n",
    "  print(\"‚úÖ Model initialized successfully!\")\n",
    "  print(f\"Model architecture: ResNet50\")\n",
    "  print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "  # Count trainable parameters\n",
    "  total_params = sum(p.numel() for p in model.parameters())\n",
    "  trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "  print(f\"Total parameters: {total_params:,}\")\n",
    "  print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "  print(f\"‚ùå Error initializing model: {e}\")\n",
    "  # Fallback: buat model sederhana jika ResNet50 gagal\n",
    "  print(\"Creating simple model as fallback...\")\n",
    "  model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64, num_classes)\n",
    "  ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918f90a",
   "metadata": {},
   "source": [
    "**Blok 10: Define Loss Function, Optimizer, dan Scheduler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeae1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with class weighting\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer with different learning rates for different parts\n",
    "optimizer = optim.AdamW([\n",
    "  {'params': model.backbone.conv1.parameters(), 'lr': 1e-5},\n",
    "  {'params': model.backbone.bn1.parameters(), 'lr': 1e-5},\n",
    "  {'params': model.backbone.layer1.parameters(), 'lr': 1e-5},\n",
    "  {'params': model.backbone.layer2.parameters(), 'lr': 1e-5},\n",
    "  {'params': model.backbone.layer3.parameters(), 'lr': 1e-4},\n",
    "  {'params': model.backbone.layer4.parameters(), 'lr': 1e-4},\n",
    "  {'params': model.backbone.fc.parameters(), 'lr': 1e-3}\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = lr_scheduler.OneCycleLR(\n",
    "  optimizer, \n",
    "  max_lr=[1e-5, 1e-5, 1e-5, 1e-5, 1e-4, 1e-4, 1e-3],\n",
    "  epochs=num_epochs,\n",
    "  steps_per_epoch=len(train_loader),\n",
    "  pct_start=0.1,\n",
    "  div_factor=10.0,\n",
    "  final_div_factor=100.0\n",
    ")\n",
    "\n",
    "print(\"Optimizer and scheduler defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518cbcf",
   "metadata": {},
   "source": [
    "**Blok 11: Training Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11faf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scheduler, device):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  correct_predictions = 0\n",
    "  total_samples = 0\n",
    "    \n",
    "  for batch_idx, (images, emotions) in enumerate(loader):\n",
    "    images, emotions = images.to(device), emotions.to(device)\n",
    "\n",
    "  # Monitor GPU memory setiap 50 batch\n",
    "    if batch_idx % 50 == 0 and torch.cuda.is_available():\n",
    "      gpu_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "      print(f'  GPU Memory: {gpu_memory:.2f} GB')\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, emotions)\n",
    "        \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "        \n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "        \n",
    "    # Statistics\n",
    "    running_loss += loss.item() * images.size(0)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct_predictions += (predicted == emotions).sum().item()\n",
    "    total_samples += emotions.size(0)\n",
    "        \n",
    "    if batch_idx % 100 == 0:\n",
    "      current_lr = scheduler.get_last_lr()[0]\n",
    "      print(f'  Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}, LR: {current_lr:.2e}')\n",
    "    \n",
    "  epoch_loss = running_loss / total_samples\n",
    "  epoch_acc = correct_predictions / total_samples\n",
    "    \n",
    "  return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct_predictions = 0\n",
    "  total_samples = 0\n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "    \n",
    "  with torch.no_grad():\n",
    "    for images, emotions in loader:\n",
    "      images, emotions = images.to(device), emotions.to(device)\n",
    "            \n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, emotions)\n",
    "            \n",
    "      running_loss += loss.item() * images.size(0)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      correct_predictions += (predicted == emotions).sum().item()\n",
    "      total_samples += emotions.size(0)\n",
    "            \n",
    "      all_preds.extend(predicted.cpu().numpy())\n",
    "      all_labels.extend(emotions.cpu().numpy())\n",
    "    \n",
    "  epoch_loss = running_loss / total_samples\n",
    "  epoch_acc = correct_predictions / total_samples\n",
    "    \n",
    "  return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=50):\n",
    "  since = time.time()\n",
    "    \n",
    "  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "  best_acc = 0.0\n",
    "  best_epoch = 0\n",
    "    \n",
    "  train_losses = []\n",
    "  train_accs = []\n",
    "  val_losses = []\n",
    "  val_accs = []\n",
    "    \n",
    "  for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "    print('-' * 60)\n",
    "        \n",
    "    # Training phase\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "        \n",
    "    # Validation phase\n",
    "    val_loss, val_acc, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "        \n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    print(f'Learning Rate: {current_lr:.2e}')\n",
    "        \n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "      best_acc = val_acc\n",
    "      best_epoch = epoch\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      torch.save(model.state_dict(), 'best_emotion_model.pth')\n",
    "      print(f'*** New best model saved! Validation Accuracy: {val_acc:.4f} ***')\n",
    "        \n",
    "    print()\n",
    "    \n",
    "  time_elapsed = time.time() - since\n",
    "  print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "  print(f'Best Validation Accuracy: {best_acc:.4f} at epoch {best_epoch + 1}')\n",
    "    \n",
    "  # Load best model weights\n",
    "  model.load_state_dict(best_model_wts)\n",
    "    \n",
    "  return model, {\n",
    "    'train_losses': train_losses,\n",
    "    'train_accs': train_accs,\n",
    "    'val_losses': val_losses,\n",
    "    'val_accs': val_accs\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49c5bf",
   "metadata": {},
   "source": [
    "**Debugging Checklist (Jalankan blok ini sebelum blok 12)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING CHECKLIST - Jalankan blok ini sebelum Blok 12\n",
    "print(\"üîç DEBUGGING CHECKLIST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check 1: Apakah model ada?\n",
    "print(\"1. Model check:\")\n",
    "if 'model' in locals():\n",
    "  print(\"   ‚úÖ Model defined\")\n",
    "  print(f\"   Model type: {type(model)}\")\n",
    "  print(f\"   Model on device: {next(model.parameters()).device}\")\n",
    "else:\n",
    "  print(\"   ‚ùå Model NOT defined - Run Block 7 first!\")\n",
    "\n",
    "# Check 2: Apakah data loaders ada?\n",
    "print(\"\\n2. Data loaders check:\")\n",
    "loaders = ['train_loader', 'val_loader', 'test_loader']\n",
    "for loader in loaders:\n",
    "  if loader in locals():\n",
    "    print(f\"   ‚úÖ {loader} defined\")\n",
    "  else:\n",
    "    print(f\"   ‚ùå {loader} NOT defined\")\n",
    "\n",
    "# Check 3: Apakah optimizer dan criterion ada?\n",
    "print(\"\\n3. Training components check:\")\n",
    "components = ['criterion', 'optimizer', 'scheduler']\n",
    "for comp in components:\n",
    "  if comp in locals():\n",
    "    print(f\"   ‚úÖ {comp} defined\")\n",
    "  else:\n",
    "    print(f\"   ‚ùå {comp} NOT defined\")\n",
    "\n",
    "# Check 4: Apakah device tersedia?\n",
    "print(\"\\n4. Device check:\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Check 5: Test forward pass\n",
    "print(\"\\n5. Forward pass test:\")\n",
    "try:\n",
    "  if 'model' in locals() and 'train_loader' in locals():\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    images, labels = sample_batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "      output = model(images)\n",
    "        \n",
    "      print(f\"   ‚úÖ Forward pass successful\")\n",
    "      print(f\"   Input shape: {images.shape}\")\n",
    "      print(f\"   Output shape: {output.shape}\")\n",
    "      print(f\"   Predicted classes: {torch.argmax(output, 1)}\")\n",
    "      print(f\"   Actual classes: {labels}\")\n",
    "except Exception as e:\n",
    "  print(f\"   ‚ùå Forward pass failed: {e}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a430c",
   "metadata": {},
   "source": [
    "**Blok 12: Training Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cadd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# DOUBLE CHECK GPU USAGE\n",
    "print(\"üîç Final GPU Verification:\")\n",
    "print(f\"Device being used: {device}\")\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "\n",
    "# Pastikan model benar-benar di GPU\n",
    "if next(model.parameters()).device.type != 'cuda':\n",
    "    print(\"‚ö†Ô∏è WARNING: Model is not on GPU! Moving to GPU...\")\n",
    "    model = model.to(device)\n",
    "    print(f\"Model moved to: {next(model.parameters()).device}\")\n",
    "\n",
    "# Test GPU dengan forward pass kecil\n",
    "print(\"\\nüß™ Testing GPU with forward pass...\")\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        # Ambil batch kecil untuk test\n",
    "        test_batch, test_labels = next(iter(train_loader))\n",
    "        test_batch = test_batch.to(device)\n",
    "        test_output = model(test_batch)\n",
    "        print(f\"‚úÖ GPU test successful!\")\n",
    "        print(f\"   Input batch shape: {test_batch.shape}\")\n",
    "        print(f\"   Output shape: {test_output.shape}\")\n",
    "        print(f\"   Batch device: {test_batch.device}\")\n",
    "        print(f\"   Output device: {test_output.device}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå GPU test failed: {e}\")\n",
    "\n",
    "# Clear GPU cache sebelum training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"üßπ GPU cache cleared\")\n",
    "\n",
    "print(\"\\nüöÄ STARTING TRAINING WITH RESNET50...\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# TRAINING EXECUTION\n",
    "try:\n",
    "    model, history = train_model(\n",
    "        model, train_loader, val_loader, criterion, \n",
    "        optimizer, scheduler, device, num_epochs\n",
    "    )\n",
    "    print(\"‚úÖ Training completed successfully!\")\n",
    "    \n",
    "    # Tampilkan best accuracy\n",
    "    best_val_acc = max(history['val_accs'])\n",
    "    print(f\"üéâ Best Validation Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e):\n",
    "        print(\"‚ùå GPU Out of Memory! Trying solutions...\")\n",
    "        # Solusi OOM: kurangi batch size\n",
    "        print(\"Reducing batch size to 32...\")\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "        \n",
    "        # Coba training lagi dengan batch size lebih kecil\n",
    "        model, history = train_model(\n",
    "            model, train_loader, val_loader, criterion, \n",
    "            optimizer, scheduler, device, num_epochs\n",
    "        )\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed with error: {e}\")\n",
    "    print(\"Trying alternative approach...\")\n",
    "    \n",
    "    # Fallback: training sederhana\n",
    "    print(\"Using simplified training...\")\n",
    "    simple_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    simple_scheduler = lr_scheduler.StepLR(simple_optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    model, history = train_model(\n",
    "        model, train_loader, val_loader, criterion, \n",
    "        simple_optimizer, simple_scheduler, device, num_epochs=30\n",
    "    )\n",
    "\n",
    "print(\"Training process completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d74ee2",
   "metadata": {},
   "source": [
    "**Blok 13: Plot Training History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8aebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_losses'], label='Train Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_accs'], label='Train Accuracy')\n",
    "plt.plot(history['val_accs'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best accuracy\n",
    "best_val_acc = max(history['val_accs'])\n",
    "best_epoch = history['val_accs'].index(best_val_acc) + 1\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "print(f\"Best Validation Accuracy (%): {best_val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae17c82",
   "metadata": {},
   "source": [
    "**Blok 14a: Evaluation pada Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97dc46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, emotions in test_loader:\n",
    "            images, emotions = images.to(device), emotions.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(emotions.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return all_preds, all_labels, all_probs\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_preds, test_labels, test_probs = evaluate_model(model, test_loader, device, class_names)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = np.mean(np.array(test_preds) == np.array(test_labels))\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "class_correct = list(0. for i in range(len(class_names)))\n",
    "class_total = list(0. for i in range(len(class_names)))\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    label = test_labels[i]\n",
    "    class_correct[label] += (test_preds[i] == label)\n",
    "    class_total[label] += 1\n",
    "\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]:10s}: {100 * class_correct[i] / class_total[i]:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
